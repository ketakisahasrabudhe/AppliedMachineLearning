{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Version Control with DVC\n",
    "\n",
    "In this notebook we track different versions of our data using DVC.\n",
    "We'll load the SMS Spam dataset, split it, then change the split and track both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize DVC\n",
    "\n",
    "We already ran `git init` and `dvc init` from the terminal before starting this notebook.\n",
    "Let's verify DVC is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVC version: 3.66.1\n"
     ]
    }
   ],
   "source": [
    "!dvc version | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data\n",
    "\n",
    "Load the SMS Spam Collection dataset and save it as raw_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages loaded: 5572\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th>0</th><td>ham</td><td>Go until jurong point, crazy.. Available only ...</td></tr>\n",
       "    <tr><th>1</th><td>ham</td><td>Ok lar... Joking wif u oni...</td></tr>\n",
       "    <tr><th>2</th><td>spam</td><td>Free entry in 2 a wkly comp to win FA Cup fina...</td></tr>\n",
       "    <tr><th>3</th><td>ham</td><td>U dun say so early hor... U c already then say...</td></tr>\n",
       "    <tr><th>4</th><td>ham</td><td>Nah I don't think he goes to usf, he lives aro...</td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the raw SMS data\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, \n",
    "                  names=['label', 'message'], encoding='latin-1')\n",
    "print(f\"Total messages loaded: {len(df)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Label counts:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw_data.csv with 5572 rows\n"
     ]
    }
   ],
   "source": [
    "# convert labels to binary and save as raw_data.csv\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "df.to_csv('raw_data.csv', index=False)\n",
    "print(f\"Saved raw_data.csv with {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Track Raw Data with DVC\n",
    "\n",
    "Now we add raw_data.csv to DVC tracking. This creates a .dvc file that stores the hash of our data, while the actual data goes into the DVC cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add raw_data.csv.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "!dvc add raw_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main ffd78c9] track raw data with dvc\n",
      " 2 files changed, 6 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 raw_data.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git add raw_data.csv.dvc .gitignore\n",
    "!git commit -m \"track raw data with dvc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Data - Version 1 (seed=42)\n",
    "\n",
    "Split into train (70%), validation (15%), test (15%) using random seed 42.\n",
    "We use stratified splitting so the class ratio stays the same across all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save(df, random_state):\n",
    "    \"\"\"\n",
    "    Split data into train/val/test and save to csv files.\n",
    "    70% train, 15% validation, 15% test with stratified splitting.\n",
    "    \"\"\"\n",
    "    # first separate out the test set\n",
    "    train_val, test = train_test_split(\n",
    "        df, test_size=0.15, random_state=random_state, stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    # then split remaining into train and validation\n",
    "    val_ratio = 0.15 / (0.70 + 0.15)\n",
    "    train, val = train_test_split(\n",
    "        train_val, test_size=val_ratio, random_state=random_state, stratify=train_val['label']\n",
    "    )\n",
    "    \n",
    "    train.to_csv('train.csv', index=False)\n",
    "    val.to_csv('validation.csv', index=False)\n",
    "    test.to_csv('test.csv', index=False)\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 split (seed=42):\n",
      "  Train:      3900 rows\n",
      "  Validation: 836 rows\n",
      "  Test:       836 rows\n",
      "\n",
      "Target distribution:\n",
      "  Train      - 0s: 3377, 1s: 523\n",
      "  Validation - 0s: 724, 1s: 112\n",
      "  Test       - 0s: 724, 1s: 112\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data.csv')\n",
    "train, val, test = split_and_save(df, random_state=42)\n",
    "\n",
    "print(\"Version 1 split (seed=42):\")\n",
    "print(f\"  Train:      {len(train)} rows\")\n",
    "print(f\"  Validation: {len(val)} rows\")\n",
    "print(f\"  Test:       {len(test)} rows\")\n",
    "print()\n",
    "print(\"Target distribution:\")\n",
    "print(f\"  Train      - 0s: {(train['label']==0).sum()}, 1s: {(train['label']==1).sum()}\")\n",
    "print(f\"  Validation - 0s: {(val['label']==0).sum()}, 1s: {(val['label']==1).sum()}\")\n",
    "print(f\"  Test       - 0s: {(test['label']==0).sum()}, 1s: {(test['label']==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Track Split Data with DVC and Tag as v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add validation.csv.dvc .gitignore train.csv.dvc test.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3319314] v1: data split with random seed 42\n",
      " 4 files changed, 18 insertions(+)\n",
      " create mode 100644 test.csv.dvc\n",
      " create mode 100644 train.csv.dvc\n",
      " create mode 100644 validation.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git add train.csv.dvc validation.csv.dvc test.csv.dvc .gitignore\n",
    "!git commit -m \"v1: data split with random seed 42\"\n",
    "!git tag v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update Split - Version 2 (seed=0)\n",
    "\n",
    "Now we change the random seed to create a different split. The class ratios will stay the same because of stratification, but the actual samples in each split will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 2 split (seed=0):\n",
      "  Train:      3900 rows\n",
      "  Validation: 836 rows\n",
      "  Test:       836 rows\n",
      "\n",
      "Target distribution:\n",
      "  Train      - 0s: 3377, 1s: 523\n",
      "  Validation - 0s: 724, 1s: 112\n",
      "  Test       - 0s: 724, 1s: 112\n"
     ]
    }
   ],
   "source": [
    "train, val, test = split_and_save(df, random_state=0)\n",
    "\n",
    "print(\"Version 2 split (seed=0):\")\n",
    "print(f\"  Train:      {len(train)} rows\")\n",
    "print(f\"  Validation: {len(val)} rows\")\n",
    "print(f\"  Test:       {len(test)} rows\")\n",
    "print()\n",
    "print(\"Target distribution:\")\n",
    "print(f\"  Train      - 0s: {(train['label']==0).sum()}, 1s: {(train['label']==1).sum()}\")\n",
    "print(f\"  Validation - 0s: {(val['label']==0).sum()}, 1s: {(val['label']==1).sum()}\")\n",
    "print(f\"  Test       - 0s: {(test['label']==0).sum()}, 1s: {(test['label']==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts are the same because stratified splitting preserves the exact class ratio. But the actual rows in each split are different -- different messages ended up in train vs test this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Track Updated Data and Tag as v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add validation.csv.dvc train.csv.dvc test.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 4a85bb5] v2: updated data split with random seed 0\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add train.csv.dvc validation.csv.dvc test.csv.dvc\n",
    "!git commit -m \"v2: updated data split with random seed 0\"\n",
    "!git tag v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Checkout Version 1 and Print Distribution\n",
    "\n",
    "Now let's go back to version 1 using DVC. We checkout the .dvc files from the v1 git tag, then run `dvc checkout` to restore the actual data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\ttest.csv\n",
      "M\ttrain.csv\n",
      "M\tvalidation.csv\n"
     ]
    }
   ],
   "source": [
    "# checkout v1 .dvc files from git, then restore the actual data\n",
    "!git checkout v1 -- train.csv.dvc validation.csv.dvc test.csv.dvc\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 (seed=42) - Target distribution:\n",
      "  train.csv      - 0s: 3377, 1s: 523\n",
      "  validation.csv - 0s: 724, 1s: 112\n",
      "  test.csv       - 0s: 724, 1s: 112\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Version 1 (seed=42) - Target distribution:\")\n",
    "print(f\"  train.csv      - 0s: {(train['label']==0).sum()}, 1s: {(train['label']==1).sum()}\")\n",
    "print(f\"  validation.csv - 0s: {(val['label']==0).sum()}, 1s: {(val['label']==1).sum()}\")\n",
    "print(f\"  test.csv       - 0s: {(test['label']==0).sum()}, 1s: {(test['label']==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Checkout Version 2 and Print Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\ttest.csv\n",
      "M\ttrain.csv\n",
      "M\tvalidation.csv\n"
     ]
    }
   ],
   "source": [
    "# checkout v2\n",
    "!git checkout v2 -- train.csv.dvc validation.csv.dvc test.csv.dvc\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 2 (seed=0) - Target distribution:\n",
      "  train.csv      - 0s: 3377, 1s: 523\n",
      "  validation.csv - 0s: 724, 1s: 112\n",
      "  test.csv       - 0s: 724, 1s: 112\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Version 2 (seed=0) - Target distribution:\")\n",
    "print(f\"  train.csv      - 0s: {(train['label']==0).sum()}, 1s: {(train['label']==1).sum()}\")\n",
    "print(f\"  validation.csv - 0s: {(val['label']==0).sum()}, 1s: {(val['label']==1).sum()}\")\n",
    "print(f\"  test.csv       - 0s: {(test['label']==0).sum()}, 1s: {(test['label']==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both versions have the same count distribution because we used stratified splitting, which preserves the class ratio. However, the actual samples in each split are different between v1 and v2 -- DVC tracked and restored the correct files for each version."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Bonus: Google Drive as Remote Storage\n\nBy default DVC stores data in a local cache (.dvc/cache). To decouple compute from storage, we can use Google Drive as a remote backend. This way the actual data files live on Google Drive and can be pulled from anywhere.\n\nFirst install the gdrive extension for DVC:\n```\npip install dvc-gdrive\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install dvc-gdrive -q",
   "metadata": {},
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Create a folder in Google Drive and copy the folder ID from the URL. The folder ID is the long string after `drive.google.com/drive/folders/`. Then add it as a DVC remote:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# google drive folder ID from the URL\nGDRIVE_FOLDER_ID = \"128DkHX4kfsXdNVKr43zgZoy4vQMU4ZAc\"\n\n!dvc remote add -d gdrive gdrive://{GDRIVE_FOLDER_ID}\n\n# to use our own GCP OAuth credentials (needed to avoid \"app blocked\" error)\n# credentials removed before pushing to github\n!dvc remote modify gdrive gdrive_client_id '<YOUR_CLIENT_ID>'\n!dvc remote modify gdrive gdrive_client_secret '<YOUR_CLIENT_SECRET>'",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# verify the remote is configured\n!dvc remote list",
   "metadata": {},
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive\tgdrive://128DkHX4kfsXdNVKr43zgZoy4vQMU4ZAc\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Now push all DVC-tracked data to Google Drive. The first time you run this it will open a browser window asking you to authenticate with your Google account.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# push data to google drive (opens browser for authentication on first run)\n!dvc push",
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n",
      "4 files pushed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Once pushed, the data is stored on Google Drive. To verify it works, we can remove the local cache and pull the data back:\n\n```\ndvc cache remove --all\ndvc pull\n```\n\nThis decouples compute from storage -- the data lives on Google Drive and can be pulled to any machine that has access to the shared folder.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# commit the remote config to git\n!git add .dvc/config\n!git commit -m \"configure google drive as dvc remote storage\"",
   "metadata": {},
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 2364369] configure google drive as dvc remote storage\n",
      " 1 file changed, 6 insertions(+)\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}